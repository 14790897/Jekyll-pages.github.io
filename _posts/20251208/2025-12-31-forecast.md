---
title: 还没把图片压坏？从傅里叶到 SVD：压缩算法背后的“数学魔法”
date: 2025-12-31
categories:
  - tech
tags:
  - 数学
  - 图像处理
  - 压缩算法
  - 傅里叶变换
---


好的，这是为你修订后的博客文章。

这次我特意补全了马尔科夫性质的数学定义公式，并对其他算法的核心公式也做了更严谨的数学表达，让整篇文章的技术含金量更高，同时保持通俗易懂。

算命的数学原理：从马尔科夫链到 Transformer 的进化史

人类总是痴迷于预测未来。

从古代的龟甲占卜，到今天的股票预测、天气预报，再到 ChatGPT 猜你下一个想说什么字，本质上我们都在做同一道数学题：条件概率。

$$P(\text{未来} | \text{过去})$$

即：已知过去发生了什么，未来发生某事的概率是多少？

虽然核心问题没变，但为了解这道题，人类在过去的一百年里，把算法从“只有金鱼记忆”进化到了拥有“上帝视角”。今天我们就来盘点一下预测算法的四个进化阶段。

第一阶段：金鱼记忆时代 (Markov Chain)

最早的预测模型非常“佛系”。19世纪末，俄国数学家安德烈·马尔科夫（Andrey Markov）提出了一个大胆的假设，这就是著名的马尔科夫性质 (Markov Property)。

核心公式

马尔科夫认为，未来的状态仅取决于当前的状态，而与更早的历史无关。用数学公式表达就是：

$$P(X_{t+1} = x | X_t = x_t, X_{t-1} = x_{t-1}, \dots, X_0 = x_0) = \mathbf{P(X_{t+1} = x | X_t = x_t)}$$

左边：本来我们要看这辈子发生的所有事 ($X_0$ 到 $X_t$) 才能预测未来 ($X_{t+1}$)。

右边：马尔科夫说不用那么麻烦，只要看现在这一刻 ($X_t$) 就够了。等号两边成立。

算法逻辑

它就像一条只有 7 秒记忆的金鱼，或者是玩“成语接龙”的人。

如果你说“车水”，我只需要看“水”字，就能接“马龙”。

我不需要知道“车水”前面是不是“一帆风顺”，也不需要关心这四个字是谁说的。

局限性：这种“遗忘”导致它无法理解长逻辑。

比如句子：“张三吃完饭，拿起纸巾擦____”。

马尔可夫模型只看得到“擦”字，它可能会预测“擦地”、“擦窗”，完全忘了主语是“张三”和动作是“吃饭”，预测不出“擦嘴”。

第二阶段：后视镜时代 (N-gram)

为了解决金鱼记忆的问题，人们想：既然看一个词不够，那我看两个、看三个行不行？

这就是 N-gram 模型。它相当于给马尔可夫装了一个**“滑动窗口”**。

核心公式

在 N-gram 中，我们假设第 $i$ 个词的出现概率，取决于它前面 $N-1$ 个词：

$$P(w_i | w_1, \dots, w_{i-1}) \approx P(w_i | \mathbf{w_{i-N+1}, \dots, w_{i-1}})$$

算法逻辑

2-gram (Bigram)：只看前 1 个词（退化为马尔科夫链）。

3-gram (Trigram)：看前 2 个词。

局限性：数据稀疏 (Data Sparsity) 与 维度爆炸。

如果你想看前 10 个词（10-gram），你需要统计 $V^{10}$ 种组合（$V$ 是词库大小）。

即使把全人类的书都读完，绝大多数长得像“我昨天在月球上吃麻辣____”这样的前缀组合你也从未见过。一旦分母为 0，模型直接死机。因此，N-gram 通常只能看前 3-4 个词，依然是个“近视眼”。

第三阶段：隐形笔记本时代 (RNN & LSTM)

既然死记硬背（N-gram）存不下那么多组合，能不能学会“理解”和“概括”？

神经网络登场了。循环神经网络 (RNN) 引入了一个革命性的概念：隐状态 (Hidden State)。

核心公式

RNN 不再查表，而是维护一个不断更新的向量 $h_t$（隐状态）：

$$h_t = \sigma(W \cdot [h_{t-1}, x_t] + b)$$

$h_t$：今天的记忆（笔记本）。

$h_{t-1}$：昨天的记忆。

$x_t$：今天输入的新信息。

含义：今天的记忆 = 消化后的昨天记忆 + 消化后的今天新闻。

算法逻辑

RNN 就像一个一边读书一边做笔记的学生。读到第一百个词时，笔记本里依然保留着第一章的“摘要”。

局限性：梯度消失 (Vanishing Gradient)。

虽然理论上它能记无限长，但实际上，随着矩阵连乘，最早的信息会被磨灭殆尽。就像复印件的复印件，最后模糊不清。RNN 还是很难记住超长距离的关联。

第四阶段：上帝视角时代 (Transformer)

2017年，Google 发表了一篇神文《Attention Is All You Need》，彻底终结了游戏。

Transformer 抛弃了“按顺序读”的旧思维，它开启了**“并行关注”**模式。

核心公式 (Scaled Dot-Product Attention)

这是目前统治 AI 界的公式：

$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

Q (Query)：我想查什么？

K (Key)：文章里的每个词贴着什么标签？

V (Value)：每个词的内容是什么？

$QK^T$：算出当前词和文中所有词的**“相关性打分”**。

算法逻辑

当预测下一个字时，Transformer 不会只看前一个字，也不会只看笔记本。它会像拥有上帝视角一样，同时扫描全文所有的字。

如果前面的句子里出现了“苹果”，现在的动词是“吃”，那么“苹果”的权重就会瞬间飙升，哪怕它们中间隔了 500 个字。

总结：从“概率统计”到“语义理解”

回顾这段进化史，你会发现人类一直在试图解决同一个矛盾：“有限的算力” vs “无限的上下文”。

马尔可夫：放弃上下文，只保算力（$P(X_{t+1}|X_t)$，只看当下）。

N-gram：用暴力统计换取一点点上下文（看几个词，遇到稀疏就挂）。

RNN：用压缩记忆换取长上下文（$h_t$，记笔记），但会遗忘。

Transformer：用暴力的算力（矩阵运算），换取了完美的全局上下文（全员注意力）。

现在的 ChatGPT、Claude，本质上就是一个读了全世界所有书、拥有超长注意力窗口、算力无穷大的超级马尔可夫模型。它不再是简单地统计概率，而是在高维向量空间里，通过数学公式“理解”了万物之间的联系。

预测未来的最好方式，就是看清当下与过去所有的纠缠。这不仅是算法，也是哲学。